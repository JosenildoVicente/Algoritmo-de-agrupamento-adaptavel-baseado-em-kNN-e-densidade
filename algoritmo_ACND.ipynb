{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "algoritmo_ACND.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gyRmYb8-RusA",
        "6eBeB6RvR1K5",
        "0V1D_ljfUFwY",
        "zzLlZoqGjNPI",
        "kB9RLLCqmag6",
        "Mq7pPygF0Lox",
        "QLqNNRWpOoX0",
        "qOteqsUOpQJY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosenildoVicente/Algoritmo-de-agrupamento-adaptavel-baseado-em-kNN-e-densidade/blob/main/algoritmo_ACND.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wHW-pDV4yiX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "import io\n",
        "import numpy.ma as ma\n",
        "from scipy.spatial import distance as dist\n",
        "\n",
        "from sklearn.neighbors import KDTree\n",
        "import statistics as stats\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDtdVmv95ctU"
      },
      "source": [
        "#Aggregation\n",
        "dataset = pd.read_csv( \"https://raw.githubusercontent.com/JosenildoVicente/Algoritmo-de-agrupamento-adaptavel-baseado-em-kNN-e-densidade/main/datasets/Aggregation.csv\", encoding=\"ISO-8859-1\" )\n",
        "#Compound\n",
        "# dataset = pd.read_csv( \"https://raw.githubusercontent.com/JosenildoVicente/Algoritmo-de-agrupamento-adaptavel-baseado-em-kNN-e-densidade/main/datasets/Compound.csv\", encoding=\"ISO-8859-1\" )\n",
        "#D31\n",
        "# dataset = pd.read_csv( \"https://raw.githubusercontent.com/JosenildoVicente/Algoritmo-de-agrupamento-adaptavel-baseado-em-kNN-e-densidade/main/datasets/D31.csv\", encoding=\"ISO-8859-1\" )\n",
        "#Flame\n",
        "# dataset = pd.read_csv( \"https://raw.githubusercontent.com/JosenildoVicente/Algoritmo-de-agrupamento-adaptavel-baseado-em-kNN-e-densidade/main/datasets/Flame.csv\", encoding=\"ISO-8859-1\" )\n",
        "#Jain\n",
        "# dataset = pd.read_csv( \"https://raw.githubusercontent.com/JosenildoVicente/Algoritmo-de-agrupamento-adaptavel-baseado-em-kNN-e-densidade/main/datasets/Jain.csv\", encoding=\"ISO-8859-1\" )\n",
        "#Pathbased\n",
        "# dataset = pd.read_csv( \"https://raw.githubusercontent.com/JosenildoVicente/Algoritmo-de-agrupamento-adaptavel-baseado-em-kNN-e-densidade/main/datasets/Pathbased.csv\", encoding=\"ISO-8859-1\" )\n",
        "#R15\n",
        "# dataset = pd.read_csv( \"https://raw.githubusercontent.com/JosenildoVicente/Algoritmo-de-agrupamento-adaptavel-baseado-em-kNN-e-densidade/main/datasets/R15.csv\", encoding=\"ISO-8859-1\" )\n",
        "#Spiral\n",
        "# dataset = pd.read_csv( \"https://raw.githubusercontent.com/JosenildoVicente/Algoritmo-de-agrupamento-adaptavel-baseado-em-kNN-e-densidade/main/datasets/Spiral.csv\", encoding=\"ISO-8859-1\" )"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpm8XvO_Ost5"
      },
      "source": [
        "#Normalização\n",
        "\n",
        "# dataset['d1'] = (dataset['d1'] - min(dataset['d1']))/(max(dataset['d1']) - min(dataset['d1']))\n",
        "# dataset['d2'] = (dataset['d2'] - min(dataset['d2']))/(max(dataset['d2']) - min(dataset['d2']))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG0eGktO6mqM"
      },
      "source": [
        "# Dataset com dados do artigo: (Sobre a etapa 5)\n",
        "testando = pd.read_csv( \"https://raw.githubusercontent.com/JosenildoVicente/Algoritmo-de-agrupamento-adaptavel-baseado-em-kNN-e-densidade/main/datasets/teste.csv\", encoding=\"ISO-8859-1\" )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyRmYb8-RusA"
      },
      "source": [
        "# Etapa 1: Read and analyze data, and determine parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY1rtM1c5FED"
      },
      "source": [
        "def etapa1(data):\n",
        "  N = data.shape[0]\n",
        "  alfa = 0.0\n",
        "  alpha = 0.0\n",
        "  beta = 0.0\n",
        "  gama = 0.0\n",
        "  # print(data[0])\n",
        "  for m in data:\n",
        "    print(min(data[m]))\n",
        "    max_s = max(data[m])\n",
        "    min_s = min(data[m])\n",
        "    rs = max_s - min_s\n",
        "    alfa += rs\n",
        "\n",
        "  alpha = N/alfa\n",
        "  beta = ((3.5 * alpha) + 45) / 100\n",
        "  gama = ( (2 * alpha) + 18)/100\n",
        "  k = max(10, int(np.ceil((N * 0.01))))\n",
        "  \n",
        "  return [N,alfa,alpha,beta,gama,k]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2Yyu6V1o9Yn",
        "outputId": "d770a77e-59a0-4db6-e6ca-96da49b5e83f"
      },
      "source": [
        "etapa1(dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.35\n",
            "1.95\n",
            "1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[788,\n",
              " 66.39999999999999,\n",
              " 11.867469879518074,\n",
              " 0.8653614457831327,\n",
              " 0.4173493975903615,\n",
              " 10]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eBeB6RvR1K5"
      },
      "source": [
        "#Etapa 2: Construct k-D Tree: kDT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENRDOp3j-9ep"
      },
      "source": [
        "def etapa2(data):\n",
        "  kdt = KDTree(data)\n",
        "  return kdt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V1D_ljfUFwY"
      },
      "source": [
        "#Etapa 3: Searches kNN of sample, calculates mean of 5NN’s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwqVeRDn_goR"
      },
      "source": [
        "def etapa3(data,N,kdt):\n",
        "  distance = []\n",
        "  knn_index = []\n",
        "  d5nn = []\n",
        "\n",
        "  distance, knn_index = kdt.query(data,N)\n",
        "\n",
        "  for i in range(len(knn_index)):\n",
        "    d5nn.append(np.mean(distance[i, 1:6]))\n",
        "\n",
        "  print(\"KNN:\")\n",
        "  for i in range(N):\n",
        "    print(distance[i][1],knn_index[i][1:16])\n",
        "\n",
        "  return [distance, knn_index, d5nn]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzLlZoqGjNPI"
      },
      "source": [
        "#Etapa 4: Calculate the global radius of SR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu-rpMk4P18y"
      },
      "source": [
        "def etapa4(d5nn):\n",
        "  d5nn = np.sort(d5nn)\n",
        "  R = max(d5nn)\n",
        "  print(\"R:\",R)\n",
        "  return [d5nn, R]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB9RLLCqmag6"
      },
      "source": [
        "#Etapa 5: Calculate sample density array(Rho)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR3IDVT-8gHr"
      },
      "source": [
        "def fab(i,j,a,b,distance):\n",
        "  d = distance[i,j]\n",
        "  if d >= 0 and d<= a:\n",
        "    return 1\n",
        "  elif d > a and d <= b:\n",
        "    return ((b-d)/ (b-a))\n",
        "  elif d > b:\n",
        "    return 0"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mGP4Mr53LC-"
      },
      "source": [
        "def etapa5(N,R,distance):\n",
        "  surrounding_region = []\n",
        "  Rho = []\n",
        "  for i in range(N):\n",
        "    Rho.append(0)\n",
        "\n",
        "  for i in range(N):\n",
        "    surrounding_region = distance[i,] < R\n",
        "    surrounding_region = distance[i,surrounding_region]\n",
        "    surrounding_mean = np.mean(surrounding_region)\n",
        "    surrounding_std_dev = stats.stdev(surrounding_region)\n",
        "    surrounding_region = np.sort(surrounding_region)\n",
        "\n",
        "    nc = len(surrounding_region)\n",
        "\n",
        "    d1 = np.mean(surrounding_region[:(np.int(np.ceil(nc*0.1))+1)])\n",
        "    d2 = min(surrounding_region[1:])\n",
        "\n",
        "    a = (d1+d2)/2\n",
        "    b = min((a+(2*surrounding_std_dev)),R)\n",
        "\n",
        "    # a = testando.a[i]\n",
        "    # b = testando.b[i]\n",
        "\n",
        "    for j in range(0,len(surrounding_region)):\n",
        "      f = fab(i,j,a,b, distance)\n",
        "      Rho[i] += f\n",
        "\n",
        "    print(i, \"nc:\",nc, \" a: %.5f\"  %a, \" b: %.5f\"%b, \" Rho: %.5f\" %Rho[i])\n",
        "  return [surrounding_region, Rho]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq7pPygF0Lox"
      },
      "source": [
        "#Etapa 6: Calculate the global density threshold(T)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8GuFmCfPUWV"
      },
      "source": [
        "def etapa6(N,rho):\n",
        "  arr = []\n",
        "  for i in range(N):\n",
        "    arr.append((rho[i], i))\n",
        "\n",
        "  arr.sort()\n",
        "  arr_invert = arr[::-1]\n",
        "\n",
        "  df_arr = pd.DataFrame(arr_invert)\n",
        "  t = np.percentile(df_arr[0], 25)\n",
        "\n",
        "  print(\"T:\",t)\n",
        "  return [t,arr_invert]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLqNNRWpOoX0"
      },
      "source": [
        "#Etapa 7: Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRmAZaf219HK"
      },
      "source": [
        "def existe(arr, valor):\n",
        "  for i in arr:\n",
        "    if i == valor:\n",
        "      return True\n",
        "  return False"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhC3SnWIe7If"
      },
      "source": [
        "# Feito 2 queue para registrar que já passou por determinada amostra, se não, entra em loop infinito\n",
        "def etapa7(N,R,arr,t,rho,k,knn_index,distance,beta,gama ):\n",
        "  order_of_cluster = 0\n",
        "  tag = []\n",
        "  for i in range(N):\n",
        "    tag.append(False)\n",
        "  queue = []\n",
        "  queue_2 = []\n",
        "\n",
        "  result = []\n",
        "  for y in range(N):\n",
        "    result.append(0)\n",
        "\n",
        "  for ind in range(N):\n",
        "    # 1 representa indice e 0 valor de arr\n",
        "    if ( tag[np.int(arr[ind][1])]):\n",
        "      continue\n",
        "    if (arr[ind][0] == 0):\n",
        "      tag[np.int(arr[ind][1])] = True\n",
        "      continue\n",
        "    if ( arr[ind][0] < t ):\n",
        "      continue\n",
        "\n",
        "    order_of_cluster += 1\n",
        "    tag[ np.int(arr[ind][1]) ] = True\n",
        "    queue.clear()\n",
        "    queue_2.clear()\n",
        "    queue.append(arr[ind][1])\n",
        "    queue_2.append(arr[ind][1])\n",
        "\n",
        "    while (len(queue) > 0):\n",
        "      i = queue.pop(0)\n",
        "\n",
        "      aver = (R + rho[np.int(i)]) / 2\n",
        "      local_t = aver * beta\n",
        "      # local_t = 0.806623\n",
        "      for e in range(k):\n",
        "        j = knn_index[np.int(i)][e]\n",
        "\n",
        "        if (distance[np.int(i)][e] > R):\n",
        "          continue\n",
        "        \n",
        "        co_nn = 0\n",
        "        for a in range(1,k):\n",
        "          for b in range(1,k):\n",
        "            if (knn_index[np.int(i)][a] == knn_index[j][b]):\n",
        "              co_nn += 1\n",
        "\n",
        "        tag[j] = True\n",
        "\n",
        "        if (rho[j]):\n",
        "          result[j] = order_of_cluster \n",
        "          if (rho[j] >= local_t and co_nn > (k * gama)):   #(Rho[j] > = localT && co_NN > k ∗γ )\n",
        "\n",
        "            if (not existe(queue_2,j)):\n",
        "              queue.append(j)\n",
        "              queue_2.append(j)\n",
        "              # print(j)\n",
        "\n",
        "  # print(\"Resultado parcial:\",result)\n",
        "\n",
        "  return [result,order_of_cluster]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOteqsUOpQJY"
      },
      "source": [
        "#Etapa 8: Post–Process clustering and save the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yegGB9ZGTfZs"
      },
      "source": [
        "def etapa8(N,order_of_cluster,result):\n",
        "\n",
        "  for cluster in range(1,order_of_cluster):\n",
        "    cont = 0\n",
        "    for i in result:\n",
        "      if (i == cluster):\n",
        "        cont += 1\n",
        "\n",
        "    if ( cont <= 5 ):\n",
        "      for j in range(N):\n",
        "        if (result[j] == cluster ):\n",
        "          result[j] = 0\n",
        "\n",
        "  resultLenToPrint = np.int(np.ceil((len(result)/10)))\n",
        "  for i in range(resultLenToPrint):\n",
        "    print(i*10,end=\" \")\n",
        "    if i == (resultLenToPrint-1):\n",
        "      for j in range(len(result)%10):\n",
        "        print(result[( (i*10) + j )],end=\" \")\n",
        "    else:\n",
        "      for j in range(10):\n",
        "        print(result[( (i*10) + j )],end=\" \")\n",
        "    print(\" \")\n",
        "\n",
        "  return result"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYwu_xGD1lKS"
      },
      "source": [
        "Plot dos gráficos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOQHIwdaaovm"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIORsL9UXG8D"
      },
      "source": [
        "def plotar(data, out,name):\n",
        "  g =sns.scatterplot(x=\"d1\", y=\"d2\",\n",
        "                hue=out,palette =\"Paired\",\n",
        "                data=data)\n",
        "  plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0)\n",
        "  plt.savefig(name+\".png\")\n",
        "  files.download(name+\".png\") \n",
        "  plt.show()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbiLW-3qWgWv"
      },
      "source": [
        "def plotarGraficos(data_in, out_acnd, out_origin, name):\n",
        "  plotar(data_in,out_origin, name+\"_correct\")\n",
        "  plotar(data_in,out_acnd, name+\"_acnd\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqxVgEZv3ZLB"
      },
      "source": [
        "# Função do algoritmo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BUQnqCF3Y18"
      },
      "source": [
        "def acnd(dataset, data_name):\n",
        "  data = dataset[['d1','d2']]\n",
        "  saida = dataset['cluster']\n",
        "  N,alfa,alpha,beta,gama,k = etapa1(data)\n",
        "  # beta = 0.35\n",
        "  # gama = 0.4\n",
        "  print([N,alfa,alpha,beta,gama,k])\n",
        "  kdt = etapa2(data)\n",
        "  # print(kdt)\n",
        "\n",
        "  distance,knn_index,d5nn = etapa3(data, N, kdt)\n",
        "  # print(distance)\n",
        "\n",
        "  d5nn, R = etapa4(d5nn)\n",
        "  # print(R)\n",
        "\n",
        "  surrounding_region, Rho = etapa5(N,R,distance)\n",
        "  # print(rho)\n",
        "  # Rho = testando.fv\n",
        "\n",
        "  T,Arr = etapa6(N,Rho)\n",
        "  # print(T)\n",
        "  # T = 4.11459\n",
        "  result, order_clusters = etapa7(N,R,Arr,T,Rho,k,knn_index,distance,beta,gama)\n",
        "\n",
        "  result = etapa8(N,order_clusters,result)\n",
        "\n",
        "  plotarGraficos(data,result,saida,data_name) "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMrMyZYvJCrU"
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "n_features = 2\n",
        "n_samples = 200\n",
        "n_clusters = 5\n",
        "\n",
        "dados_blobs = make_blobs(n_samples=n_samples, centers=n_clusters, n_features=n_features,random_state=0)\n",
        "\n",
        "dataset_1 = {}\n",
        "\n",
        "dataset_1['d1'] = []\n",
        "dataset_1['d2'] = []\n",
        "dataset_1['cluster'] = []\n",
        "for i in range(n_samples):\n",
        "  dataset_1['d1'].append(dados_blobs[0][i][0])\n",
        "  dataset_1['d2'].append(dados_blobs[0][i][1])\n",
        "  dataset_1['cluster'].append(dados_blobs[1][i])\n",
        "print(dataset_1)\n",
        "\n",
        "df = pd.DataFrame.from_dict(dataset_1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK0PFsinMyQB"
      },
      "source": [
        "# acnd(df)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM9CAC_w56iZ"
      },
      "source": [
        "acnd(dataset,\"Aggregation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MeP1K8QZnms"
      },
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import Birch\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "clusterss_number = len(dataset['cluster'].unique())\n",
        "\n",
        "clustering = DBSCAN(eps=2,min_samples=2).fit_predict(dataset)\n",
        "brc = Birch(n_clusters=clusterss_number,threshold=0.5)\n",
        "brc.fit(dataset)\n",
        "y_brc = brc.predict(dataset)\n",
        "KMeans_model = KMeans(n_clusters=clusterss_number,random_state=0).fit(dataset)\n",
        "y_kmeans = KMeans_model.predict(dataset)\n",
        "\n",
        "\n",
        "data = dataset[['d1','d2']]\n",
        "\n",
        "nome = \"\" #Colocar nome do dataset que estiver utilizando\n",
        "\n",
        "plotar(data,clustering,nome+ \"_DBSCAN\")\n",
        "plotar(data,y_brc,nome+ \"_Birch\")\n",
        "plotar(data,y_kmeans,nome+ \"_KMeans\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}